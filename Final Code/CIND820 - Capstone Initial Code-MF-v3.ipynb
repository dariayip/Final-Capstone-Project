{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41a82cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import ydata_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f3d6dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we only need 3 columns in review.json. Since the file is so big (5GB!) we will avoid opening the whole JSON file\n",
    "#and instead append to a list and then make it into a dataframe\n",
    "\n",
    "#ADD IN REVIEW JSON\n",
    "\n",
    "chunk = []\n",
    "columns = [\"user_id\", \"business_id\", \"stars\"] #We only need these columns\n",
    "\n",
    "with open(\"/Users/dariayip/Documents/vs code/yelp_academic_dataset_review.json\", \"r\") as y:\n",
    "    for line in y:\n",
    "        doc = json.loads(line)\n",
    "        lst = [doc[\"user_id\"], doc[\"business_id\"], doc[\"stars\"]]\n",
    "        chunk.append(lst)\n",
    "\n",
    "review = pd.DataFrame(data=chunk, columns=columns)\n",
    "\n",
    "review.rename(columns={\"stars\": \"stars_review\"}, inplace=True) #rename stars to stars review to avoid confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24120a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_dtypes = {\"business_id\" : str, \"name\" : str, \"address\" : str, \"city\" : str, \"state\" : str, \"postal_code\" : str,\n",
    "                  \"latitude\" : float, \"longitude\" : float, \"stars\" : float, \"review_count\" : int, \"is_open\" : int,\n",
    "                  \"attributes\" : str, \"categories\" : str, \"hours\" : str}\n",
    "\n",
    "#Open the Business JSON, with orient as columns --> values in that ordered pair\n",
    "with open(\"/Users/dariayip/Documents/vs code/yelp_academic_dataset_business.json\", \"r\") as y:\n",
    "    business = pd.read_json(y, orient=\"records\", lines = True,  dtype = business_dtypes) #save as a business df\n",
    "\n",
    "business.rename(columns={\"stars\": \"stars_business\"}, inplace=True) #rename stars to stars biz to avoid confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "120110c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform a left join to get the businesses with reviews and add the columns in the business \n",
    "businesseswithreviews = pd.merge(review, business, on = \"business_id\", how = \"left\")\n",
    "#This is done to merge all relevant information into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8c7b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsampling\n",
    "\n",
    "businesseswithreviews = businesseswithreviews[businesseswithreviews[\"is_open\"] == 1] #drop any businesses that are no longer operational\n",
    "businesseswithreviews = businesseswithreviews[businesseswithreviews[\"categories\"].str.contains(\"Restaurants\", na=False)] #Delete any businesses that do not include the word \"Restaurants\" within the Categories section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4eae07d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(511138, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(499171, 16)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downsampling Part 2\n",
    "\n",
    "businesseswithreviews = businesseswithreviews[businesseswithreviews[\"city\"] == \"Philadelphia\"] #filter out any cities other than Philadelphia (most businesses by city)\n",
    "print(businesseswithreviews.shape)\n",
    "\n",
    "#Group by business_id and count the number of reviews per business with the .transform(len)\n",
    "counts_business_id = businesseswithreviews.groupby(\"business_id\")[\"business_id\"].transform(len)\n",
    "counter = (counts_business_id > 20)\n",
    "businesseswithreviews = businesseswithreviews[counter]\n",
    "businesseswithreviews.shape\n",
    "#remove businesses with less than 20 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "de47d05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448906, 16)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Systematic Sampling (removing every 10th row)\n",
    "businesseswithreviews = businesseswithreviews[businesseswithreviews.index % 10 != 0] \n",
    "businesseswithreviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7f0a966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89781, 16)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Sampling of 20% of dataset\n",
    "businesseswithreviews = businesseswithreviews.sample(frac=0.20)\n",
    "businesseswithreviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e154aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id           0\n",
      "business_id       0\n",
      "stars_review      0\n",
      "name              0\n",
      "address           0\n",
      "city              0\n",
      "state             0\n",
      "postal_code       0\n",
      "latitude          0\n",
      "longitude         0\n",
      "stars_business    0\n",
      "review_count      0\n",
      "is_open           0\n",
      "attributes        0\n",
      "categories        0\n",
      "hours             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Detect any missing data\n",
    "missingdata = businesseswithreviews.isnull().sum() #sum up the amount of missing data points in this dataframe\n",
    "print(missingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d0c606e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id       0\n",
      "name              0\n",
      "address           0\n",
      "city              0\n",
      "state             0\n",
      "postal_code       0\n",
      "latitude          0\n",
      "longitude         0\n",
      "stars_business    0\n",
      "review_count      0\n",
      "is_open           0\n",
      "attributes        0\n",
      "categories        0\n",
      "hours             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Detect any missing data\n",
    "missingdata = business.isnull().sum() #sum up the amount of missing data points in this dataframe\n",
    "print(missingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c12975cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id         0\n",
      "business_id     0\n",
      "stars_review    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Detect any missing data\n",
    "missingdata = review.isnull().sum() #sum up the amount of missing data points in this dataframe\n",
    "print(missingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71e17695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c4d5b87ba5403a82b64686befbe78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/scipy/stats/_stats_py.py:112: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3d859255654165ac85ec7d8212dcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b8c992489a44be83763b12bae6e0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1d37f1453c4bf59b29db662a3bece2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pandas Profile for the businesseswithreviews dataset\n",
    "profile = ydata_profiling.ProfileReport(businesseswithreviews)\n",
    "profile.to_file(output_file=\"businesseswithreviewsEDAprofile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0b89009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(line_format='user item rating', rating_scale=(1, 5)) #using the rating scale to ensure it stays as\n",
    "#1 to 5\n",
    "dataset = Dataset.load_from_df(businesseswithreviews[[\"user_id\", \"name\", \"stars_review\"]], reader)\n",
    "\n",
    "#Split the dataset into train and test sets before we preprocess the data using Surprise to 80/20\n",
    "df_train, df_test = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0dda7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "method = SVD()\n",
    "method.fit(df_train)  #An alternative is to use ALS. Training the model here\n",
    "recommendations = method.test(df_test) #generate recs by using SVD on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "40f067ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.9478\n",
      "RMSE: 1.1941\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "#Using Surprise, we can calculate RMSE and MAE to evaluate our recommendation system\n",
    "\n",
    "# totalmae = 0\n",
    "# totalrmse = 0\n",
    "\n",
    "# for i in range(5): #loop 5 times and take average\n",
    "MAE = accuracy.mae(recommendations)\n",
    "totalmae += MAE\n",
    "RMSE = accuracy.rmse(recommendations)\n",
    "totalrmse += RMSE\n",
    "    \n",
    "# #Arithmetic Average\n",
    "# totalmae = totalmae/5\n",
    "# totalrmse = totalrmse/5\n",
    "\n",
    "# print(\"\\nAverage RMSE:\", totalrmse, \"\\nAverage MAE:\", totalmae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3700ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 1.1932333333333334 \n",
      "Average MAE: 0.9475333333333333\n"
     ]
    }
   ],
   "source": [
    "totalmae = [0.9398, 0.9509, 0.9519]\n",
    "totalrmse = [1.1845, 1.1976, 1.1976]\n",
    "\n",
    "averagemae = sum(totalmae)/len(totalmae)\n",
    "averagermse = sum(totalrmse)/len(totalrmse)\n",
    "\n",
    "print(\"Average RMSE:\", averagermse, \"\\nAverage MAE:\", averagemae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a630e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will try ALS to see if this changes anything\n",
    "from surprise import SVDpp\n",
    "from surprise import BaselineOnly #predicts the baseline estimate given a user and item\n",
    "\n",
    "#Using ALS below to see if there is any difference. Figures are from Surprise documentation\n",
    "bsl_options = {\"method\": \"als\", \"n_epochs\": 5, \"reg_u\": 12, \"reg_i\": 5}\n",
    "algo = BaselineOnly(bsl_options=bsl_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a480596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1924  1.1956  1.1912  1.1975  1.1861  1.1926  0.0039  \n",
      "MAE (testset)     0.9512  0.9504  0.9443  0.9516  0.9413  0.9478  0.0042  \n",
      "Fit time          0.56    0.54    0.56    0.54    0.56    0.55    0.01    \n",
      "Test time         0.04    0.04    0.04    0.04    0.04    0.04    0.00    \n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "results = cross_validate(method, dataset, measures = [\"RMSE\", \"MAE\"], cv = 5, verbose = True) #verbose = True to print the progress\n",
    "#and results of each fold\n",
    "\n",
    "#This is to use k-fold cross validation to evaluate our model as another way to evaluate other than what was shown \n",
    "#above with test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4869c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "meanrmse = results[\"test_rmse\"]\n",
    "meanmae = results[\"test_mae\"]\n",
    "\n",
    "folds = (\"1st Fold\", \"2nd Fold\", \"3rd Fold\", \"4th Fold\", \"5th Fold\")\n",
    "x_axis = folds #for the x-coordinates for the graph\n",
    "y_axis = meanrmse.tolist()\n",
    "y_axis_mae = meanmae.tolist()\n",
    "\n",
    "plt.bar(x_axis, y_axis, label = \"RMSE\", color = \"pink\")\n",
    "plt.plot(x_axis, y_axis_mae, label = \"MAE\", marker='o', color = \"black\") #marker = 'o' used to \n",
    "#plt.show() #having trouble showing this so saved as PNG file instead\n",
    "plt.legend() #add a legend\n",
    "\n",
    "plt.savefig(\"rmsemaeresults.png\") #mae is represented by the line graph and rmse by the bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10521ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
